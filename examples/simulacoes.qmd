---
title: "Simulações"
format: html
editor: visual
execute: 
  cache: true
---

```{r}

# install.packages("devtools")
# install.packages("tidyverse")
# detach("package:mixRegEM")
# try(remove.packages("mixRegEM"))
# devtools::install_github("PedroHCAlmeida/mixRegEM")
```

```{r}
matrizP <- function(alpha, R){
  P1 <- exp(R%*%alpha)/(1 + rowSums(exp(R%*%alpha)))
  P <- cbind(P1, 1 - rowSums(P1))
  return(P)
}

# Função auxiliar
cbind.fill <- function(...){
  nm <- list(...) 
  nm <- lapply(nm, as.matrix)
  n <- max(sapply(nm, nrow)) 
  do.call(cbind, lapply(nm, function (x) 
    rbind(x, matrix(, n-nrow(x), ncol(x))))) 
}
```

# Grupos pobremente separados

## Gerando grupo 1

```{r}
set.seed(123)
n = 3000
X = cbind(rep(1, n), rnorm(n, 5, 3), rnorm(n, 10, 5))
x = X[,-1]

R = cbind(rep(1, n), runif(n, -2, 1), runif(n, -1, 1))
r = R[,-1]

beta01 <- c(11, 6, -1)
alpha01 <- c(0.7, 1, 2)
sigma01 <- 100
mu01 <- X%*%beta01

alpha <- matrix(alpha01, byrow = T, nrow = 3)
P <- matrizP(alpha, R)
```

## Gerando grupo 2

```{r}
beta02 <- c(-10, 1, 7)
sigma02 <- 30
mu02 <- X%*%beta02
```

## Gerando Y

```{r}
obs = do.call(rbind, 
              lapply(1:n,
                     function(i){
                       mixsmsn::rmix(1, pii = P[i,], family = 'Normal', cluster = T,
                                     arg = list(c(mu01[i,], sqrt(sigma01), 0), 
                                                c(mu02[i,], sqrt(sigma02), 0)))
                     }))

y = unlist(obs[,1])

grupo = unlist(obs[,2]) 
```

# Analisando Grupos

```{r}
data.frame(grupo = as.factor(grupo), y = y) |>
  ggplot2::ggplot() +
  ggplot2::aes(x = y, fill = grupo) +
  ggplot2::geom_histogram(bins = 15, alpha=0.6, position = 'identity') +
  ggplot2::theme_minimal()
```

## Regressão Usual

```{r}
ml = lm(y ~ ., data.frame(cbind(x, y = y)))
summary(ml) 
```

## Modelo de misturas normal

```{r}
regMix = mixRegEM::regEM(y, x, g = 2, tol = 1E-6, grupoReal = grupo, verbose = F,
                         family = "MixNormal", initGrupo = "KMeans", min_iter = 1)

regMix$Parametros |>
  kableExtra::kable("html") |>
  kableExtra::kable_styling(font_size = 14) |>
  kableExtra::scroll_box(width = "100%", height = "600px")
```


## Modelo de misturas de experts normal

```{r}
regMoe = mixRegEM::regEM(y, x, r = r, g = 2, tol = 1E-6, grupoReal = grupo, verbose = F,
                         family = "MoENormal", initGrupo = "KMeans", min_iter = 1)

regMoe$Parametros |>
  kableExtra::kable("html")|>
  kableExtra::kable_styling(font_size = 14) |>
  kableExtra::scroll_box(width = "100%", height = "600px")
```

## Comparação modelos

```{r}
regMix$Parametros |>
  t() |>
  as.data.frame() |>
  tibble::rownames_to_column("Grupo") |>
  tidyr::pivot_longer(-Grupo, names_to = "Coeficiente",
                      values_to = "Mix") |>
  dplyr::left_join(regMoe$Parametros |>
                     t() |> 
                     as.data.frame() |>
                     tibble::rownames_to_column("Grupo") |>
                     tidyr::pivot_longer(-Grupo, names_to = "Coeficiente",
                                          values_to = "Moe") |>
                     dplyr::filter(!grepl("alpha", Coeficiente)), by = c("Grupo", "Coeficiente")) |>
  cbind("Simulação" = c(beta01, sqrt(sigma01), beta02, sqrt(sigma02))) |>
  kableExtra::kable("html") |>
  kableExtra::kable_styling(font_size = 14) |>
  kableExtra::scroll_box(width = "100%", height = "600px")
```


## Predição

### Ponderação

```{r}
set.seed(938)
train_indexes = sample(1:n, n*0.7)

reg_moe_train = mixRegEM::regEM(y[train_indexes], 
                                x[train_indexes,], 
                                r = r[train_indexes,], g = 2, 
                                tol = 1E-6, verbose = F,
                                family = "MoENormal", initGrupo = "KMeans")

test_predict_pond = mixRegEM::predictMix(reg = reg_moe_train, 
                                         x = x[!(1:n) %in%train_indexes,],
                                         r = r[!(1:n) %in%train_indexes,],
                                         class = F)
 # residuos
(test_predict_pond - y[!(1:n) %in%train_indexes]) |>
  hist()
```

```{r}
(test_predict_pond - y[!(1:n) %in%train_indexes]) |>
  summary()
```


```{r}
mean((test_predict_pond - y[!(1:n) %in%train_indexes])**2)
```

### Classificação

```{r}
test_predict_class = mixRegEM::predictMix(reg = reg_moe_train, 
                                         x = x[!(1:n) %in%train_indexes,],
                                         r = r[!(1:n) %in%train_indexes,],
                                         class = T)
 # residuos
(test_predict_class - y[!(1:n) %in%train_indexes]) |>
  hist()
```

```{r}
(test_predict_class - y[!(1:n) %in%train_indexes]) |>
  summary()
```

```{r}
mean((test_predict_class - y[!(1:n) %in%train_indexes])**2)
```


### Modelo sem grupos

```{r}
ml_train = lm(y[train_indexes] ~ x[train_indexes,])
y_ml = t(ml_train$coefficients %*% t(X[!(1:n) %in%train_indexes,]))

(y_ml - y[!(1:n) %in% train_indexes]) |>
  hist(xlim = c(-110, 110))
```

```{r}
(y_ml - y[!(1:n) %in% train_indexes]) |> 
  summary()
```

```{r}
mean((y_ml - y[!(1:n) %in%train_indexes])**2)
```

```{r}
set.seed(563)
gera_moe_amostra = function(){
  n = 3000
  X = cbind(rep(1, n), rnorm(n, 5, 3), rnorm(n, 10, 5))
  x = X[,-1]
  
  R = cbind(rep(1, n), runif(n, -2, 1), runif(n, -1, 1))
  r = R[,-1]
  
  beta01 <- c(11, 6, -1)
  alpha01 <- c(0.7, 1, 2)
  sigma01 <- 100
  mu01 <- X%*%beta01
  
  alpha <- matrix(alpha01, byrow = T, nrow = 3)
  P <- matrizP(alpha, R)
  
  obs = do.call(rbind, 
              lapply(1:n,
                     function(i){
                       mixsmsn::rmix(1, pii = P[i,], family = 'Normal', cluster = T,
                                     arg = list(c(mu01[i,], sqrt(sigma01), 0), 
                                                c(mu02[i,], sqrt(sigma02), 0)))
                     }))

  y = unlist(obs[,1])
  
  return(list(x = x, r = r, y = y))
}
```

```{r}
amostras = replicate(1000, gera_moe_amostra()) |>
  t()

amostras |>
  head()
```

```{r}
train_test_metrics = function(amostra){
  
  y = amostra$y
  x = amostra$x
  r = amostra$r
  n = length(y)
  
  train_indexes = sample(1:n, n*0.7)

  reg_moe_train = mixRegEM::regEM(y[train_indexes], 
                                x[train_indexes,], 
                                r = r[train_indexes,], g = 2, 
                                tol = 1E-6, verbose = F,
                                family = "MoENormal", initGrupo = "KMeans")

  test_predict_pond = mixRegEM::predictMix(reg = reg_moe_train, 
                                         x = x[!(1:n) %in%train_indexes,],
                                         r = r[!(1:n) %in%train_indexes,],
                                         class = F)
  
  test_predict_class = mixRegEM::predictMix(reg = reg_moe_train, 
                                         x = x[!(1:n) %in%train_indexes,],
                                         r = r[!(1:n) %in%train_indexes,],
                                         class = T)
  
  ml_train = lm(y[train_indexes] ~ x[train_indexes,])
  y_ml = t(ml_train$coefficients %*% t(X[!(1:n) %in%train_indexes,]))
  
  eqm_ml = mean((y_ml - y[!(1:n) %in%train_indexes])**2)
  eqm_class = mean((test_predict_class - y[!(1:n) %in% train_indexes])**2)
  eqm_pond = mean((test_predict_pond - y[!(1:n) %in%train_indexes])**2)
  
  return(cbind("pond" = eqm_pond, "class" = eqm_class, "ml" = eqm_ml))
}
```

```{r}
set.seed(0981)
eqms = amostras |>
  apply(1, train_test_metrics) |>
  t()

eqms |>
  head()
```

```{r}
eqms |>
  apply(2, summary)
```





























